# Docker Production Configuration Template
# Copy this file to config/pipeline_config.yaml and customize for your environment

# =============================================================================
# PIPELINE CONFIGURATION
# =============================================================================
pipeline:
  name: "RAG Evaluation Pipeline - Docker Production"
  version: "1.0.0"
  description: "Production Docker deployment configuration"
  environment: "docker"
  run_id: "production_eval_${TIMESTAMP}"

# =============================================================================
# DATA SOURCES
# =============================================================================
data_sources:
  documents:
    # Primary documents for evaluation (mounted as volume)
    primary_docs:
      - "/app/data/documents/your_document.pdf"
      # Add more documents as needed
      # - "/app/data/documents/document2.pdf"
      # - "/app/data/documents/document3.docx"
    
    # Optional: Additional directories
    additional_dirs: []
    
    # Supported file types
    file_types: ["pdf", "docx", "txt"]
    
    # Batch processing configuration
    batch_processing:
      enabled: true
      max_concurrent_files: 4
      chunk_size: 1000
      chunk_overlap: 100

# =============================================================================
# RAG SYSTEM CONFIGURATION
# =============================================================================
rag_system:
  # Docker network configuration
  # Use host.docker.internal to access host services from container
  api_endpoint: "http://host.docker.internal:8000/api/query"
  
  # Request/response format
  request_format:
    question_key: "query"
    response_key: "answer"
    contexts_key: "sources"
  
  # Connection settings
  timeout: 30
  retry_attempts: 3
  retry_delay: 1

# =============================================================================
# TESTSET GENERATION
# =============================================================================
testset_generation:
  # Hybrid method combines configurable and RAGAS approaches
  method: "hybrid"  # Options: "configurable", "ragas", "hybrid"
  
  # Sample configuration
  samples_per_document: 100
  max_total_samples: 1000
  
  # Question type distribution
  question_types:
    simple: 0.3
    multi_context: 0.3
    reasoning: 0.4
  
  # Keyword extraction configuration
  keyword_extraction:
    methods: ["keybert", "yake", "spacy_entities"]
    min_keywords: 3
    max_keywords: 10
    
    # Domain-specific keywords (optional)
    domain_keywords:
      enabled: false
      terms: []
  
  # RAGAS configuration for advanced testset generation
  ragas_config:
    use_custom_llm: false
    use_openai: false
    embeddings_model: "sentence-transformers/all-MiniLM-L6-v2"
    
    # Custom LLM configuration (when use_custom_llm: true)
    custom_llm:
      endpoint: "http://host.docker.internal:8001/v1/chat/completions"
      api_key_file: "/app/config/secrets.yaml"
      api_key_path: "custom_llm.api_key"
      model: "your-model-name"
      temperature: 0.3
      max_tokens: 1000

# =============================================================================
# EVALUATION CONFIGURATION
# =============================================================================
evaluation:
  # Evaluation methods
  methods:
    contextual_keywords: true
    ragas_metrics: true
    semantic_similarity: true
    human_feedback: false  # Disable for automated production runs
  
  # Threshold configuration
  thresholds:
    contextual_threshold: 0.6
    ragas_threshold: 0.7
    semantic_threshold: 0.6
  
  # Pass criteria
  pass_criteria: "majority"  # Options: "all", "majority", "any"
  
  # RAGAS metrics configuration
  ragas_metrics:
    enabled: true
    metrics: ["faithfulness", "answer_relevancy", "context_precision", "context_recall"]
    
  # Human feedback configuration (disabled in production)
  human_feedback:
    enabled: false
    uncertainty_threshold: 0.3
    max_feedback_samples: 50

# =============================================================================
# OUTPUT CONFIGURATION
# =============================================================================
output:
  # Base output directory (container path)
  base_dir: "/app/outputs"
  
  # Output formats
  formats:
    testsets: "xlsx"  # Options: "csv", "xlsx", "json"
    evaluations: "xlsx"
    reports: "html"
  
  # Report configuration
  reports:
    generate_executive_summary: true
    generate_technical_analysis: true
    generate_visualizations: true
    include_raw_data: true
  
  # Visualization settings
  visualizations:
    save_plots: true
    plot_format: "png"
    plot_dpi: 300
    include_interactive: false  # Disable for production

# =============================================================================
# PERFORMANCE CONFIGURATION
# =============================================================================
performance:
  # Parallel processing
  max_workers: 2  # Adjust based on container CPU allocation
  use_multiprocessing: true
  
  # Memory management
  batch_processing: true
  max_memory_usage: "2GB"
  
  # Caching
  cache_enabled: true
  cache_dir: "/app/cache"
  model_cache_size: "1GB"

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================
logging:
  level: "INFO"  # Options: "DEBUG", "INFO", "WARNING", "ERROR"
  
  # Log files (container paths)
  file_path: "/app/logs/pipeline.log"
  error_file_path: "/app/logs/pipeline_errors.log"
  
  # Log rotation
  max_file_size: "10MB"
  backup_count: 5
  
  # Console output
  console_output: true
  console_format: "%(asctime)s - %(name)s - %(levelname)s - %(message)s"
  
  # Detailed logging for debugging
  detailed_logging:
    enabled: false
    include_timestamps: true
    include_traceback: true

# =============================================================================
# DOCKER-SPECIFIC CONFIGURATION
# =============================================================================
docker:
  # Container environment settings
  environment:
    pythonunbuffered: true
    cache_dir: "/app/cache"
    temp_dir: "/app/temp"
  
  # Resource monitoring
  monitoring:
    enabled: true
    log_resource_usage: true
    memory_threshold: "3GB"
    cpu_threshold: 80
  
  # Health check configuration
  health_check:
    enabled: true
    interval: 30
    timeout: 10
    retries: 3

# =============================================================================
# SECURITY CONFIGURATION
# =============================================================================
security:
  # API key management
  secrets_file: "/app/config/secrets.yaml"
  
  # Input validation
  validate_inputs: true
  sanitize_outputs: true
  
  # File access restrictions
  restrict_file_access: true
  allowed_extensions: [".pdf", ".docx", ".txt"]
  max_file_size: "100MB"

# =============================================================================
# NOTIFICATION CONFIGURATION (Optional)
# =============================================================================
notifications:
  enabled: false
  
  # Email notifications
  email:
    enabled: false
    smtp_server: "smtp.gmail.com"
    smtp_port: 587
    sender_email: "pipeline@yourcompany.com"
    recipients: ["admin@yourcompany.com"]
  
  # Webhook notifications
  webhook:
    enabled: false
    url: "https://your-webhook-endpoint.com/pipeline-status"
    headers:
      Authorization: "Bearer your-token"

# =============================================================================
# EXPERIMENTAL FEATURES (Optional)
# =============================================================================
experimental:
  # Advanced evaluation features
  advanced_evaluation:
    enabled: false
    custom_metrics: []
  
  # API mode (future feature)
  api_mode:
    enabled: false
    port: 8080
    host: "0.0.0.0"
  
  # Distributed processing (future feature)
  distributed:
    enabled: false
    workers: 1
